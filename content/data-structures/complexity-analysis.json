{
  "title": "Time & Space Complexity",
  "slug": "complexity-analysis",
  "subject": "Data Structures",
  "category": "Core Computer Science",
  "level": "Beginner",
  "estimated_read_time": "20 mins",
  "prerequisites": [
    "Programming Basics"
  ],
  "learning_objectives": [
    "Efficiency",
    "Input Size (n)",
    "Dominant Term"
  ],
  "theory": "How does the algorithm scale as input size `n` grows? \n- **Time Complexity**: Number of operations.\n- **Space Complexity**: Memory usage.\nWe focus on the rate of growth, ignoring constants.",
  "syntax": "f(n) = n^2 + 5n + 10",
  "examples": [
    {
      "code": "for i in range(n):\n  print(i)",
      "output": "O(n)",
      "explanation": "Runs 'n' times."
    }
  ],
  "common_mistakes": [],
  "interview_questions": [
    {
      "question": "Which is better: O(1) or O(log n)?",
      "answer": "O(1) (Constant time) is better than O(log n).",
      "difficulty": "Easy"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "Ignore constants.",
    "Ignore lower order terms."
  ],
  "summary": "Analyzing complexity prevents writing code that hangs when data grows."
}