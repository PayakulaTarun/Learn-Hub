{
  "title": "Data Science with Big Data",
  "slug": "big-data-science",
  "subject": "Data Science",
  "category": "Data & Analytics",
  "level": "Advanced",
  "estimated_read_time": "25 mins",
  "prerequisites": [
    "Probability Basics"
  ],
  "learning_objectives": [
    "Spark (PySpark)",
    "Hadoop Ecosystem",
    "Distributed Computing"
  ],
  "theory": "When data exceeds RAM (Big Data), Pandas fails. Tools like **Apache Spark** distribute data across a cluster of machines. PySpark allows writing Python code that executes in parallel.",
  "syntax": "spark.read.parquet(...)",
  "examples": [],
  "common_mistakes": [
    {
      "mistake": "Bringing all data to driver",
      "correction": "`.collect()` brings distributed data to the master node. If large, it crashes the app. Keep data distributed.",
      "example": "OOM Error."
    }
  ],
  "interview_questions": [
    {
      "question": "MapReduce vs Spark?",
      "answer": "Spark processes in-memory (100x faster). MapReduce writes to disk at every step.",
      "difficulty": "Medium"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "Lazy evaluation.",
    "RDDs vs DataFrames."
  ],
  "summary": "Big Data tools allows Data Science to scale to petabytes.",
  "order": 25
}