{
  "title": "Introduction to Deep Learning",
  "slug": "deep-learning-intro",
  "subject": "Data Science",
  "category": "Data & Analytics",
  "level": "Advanced",
  "estimated_read_time": "35 mins",
  "prerequisites": [
    "Neural Networks Basics"
  ],
  "learning_objectives": [
    "Neural Networks",
    "Activation Functions",
    "Backpropagation",
    "TensorFlow/PyTorch"
  ],
  "theory": "Deep Learning uses multi-layer neural networks to learn representations. It excels at unstructured data (Images, Text). \nKey: **Backpropagation** calculates gradients to update weights via Gradient Descent.",
  "syntax": "keras.Sequential()",
  "examples": [],
  "common_mistakes": [
    {
      "mistake": "Using DL on small tabular data",
      "correction": "XGBoost usually beats Deep Learning on structured tables. DL needs huge data to shine.",
      "example": "Overkill."
    }
  ],
  "interview_questions": [
    {
      "question": "What is the Vanishing Gradient problem?",
      "answer": "In deep networks with sigmoid/tanh, gradients become zero during backprop, stopping training. ReLU fixes this.",
      "difficulty": "Advanced"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [
    {
      "scenario": "Computer Vision",
      "description": "Detecting cancer in X-rays.",
      "code": "CNN"
    }
  ],
  "exam_notes": [
    "ReLU is standard activation.",
    "Needs GPU."
  ],
  "summary": "Deep Learning powers the current AI revolution (LLMs, GenAI)."
}