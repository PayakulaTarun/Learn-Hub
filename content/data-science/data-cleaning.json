{
  "title": "Data Cleaning Basics",
  "slug": "data-cleaning",
  "subject": "Data Science",
  "category": "Data & Analytics",
  "level": "Beginner",
  "estimated_read_time": "20 mins",
  "prerequisites": [
    "Pandas Introduction"
  ],
  "learning_objectives": [
    "Identify Dirty Data",
    "df.info()",
    "df.describe()",
    "Duplicates"
  ],
  "theory": "Real-world data is messy. Cleaning involves fixing inconsistency, removing duplicates, and handling wrong types. `df.info()` checks types and nulls. `df.describe()` checks statistical summaries for anomalies.",
  "syntax": "df.drop_duplicates()\ndf.astype('int')",
  "examples": [
    {
      "code": "df.drop_duplicates(subset=['id'], keep='first')",
      "output": "Unique DataFrame",
      "explanation": "Removes duplicate rows based on the 'id' column."
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Not assigning result",
      "correction": "Most Pandas operations return a new object. You must assign it back: `df = df.drop_duplicates()` or use `inplace=True`.",
      "example": "df.drop_duplicates()  # Does nothing to df"
    }
  ],
  "interview_questions": [
    {
      "question": "Why is data cleaning important?",
      "answer": "Garbage In, Garbage Out (GIGO). Models trained on dirty data will yield incorrect predictions.",
      "difficulty": "Easy"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "Check dtypes.",
    "Check uniqueness."
  ],
  "summary": "Data cleaning is the most time-consuming but critical part of the job.",
  "order": 10
}