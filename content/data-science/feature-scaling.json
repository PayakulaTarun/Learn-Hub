{
  "title": "Feature Scaling",
  "slug": "data-science-feature-scaling",
  "subject": "Data Science",
  "category": "Data & Analytics",
  "level": "Intermediate",
  "estimated_read_time": "20 mins",
  "prerequisites": [
    "Feature Engineering"
  ],
  "learning_objectives": [
    "Normalization (MinMax)",
    "Standardization (Z-Score)",
    "When to use which?"
  ],
  "theory": "Models based on distance (KNN, K-Means, SVM) or Gradient Descent perform poorly if features have different scales (e.g., Age 1-100 vs Salary 10000-100000).\n- **MinMax**: Scales to [0, 1].\n- **Standard**: Scales to Mean=0, Std=1.",
  "syntax": "StandardScaler().fit_transform(X)",
  "examples": [],
  "common_mistakes": [
    {
      "mistake": "Fitting scaler on Test data",
      "correction": "Fit only on Training data. Transform both Train and Test. Prevents data leakage.",
      "example": "scaler.fit(X_test) // BAD"
    }
  ],
  "interview_questions": [],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "Tree models don't need scaling.",
    "Neural Nets require scaling."
  ],
  "summary": "Scaling ensures all features contribute equally to the result.",
  "order": 28
}