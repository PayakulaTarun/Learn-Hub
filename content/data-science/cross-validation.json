{
  "title": "Train-Test Split & Cross Validation",
  "slug": "data-science-cross-validation",
  "subject": "Data Science",
  "category": "Data & Analytics",
  "level": "Intermediate",
  "estimated_read_time": "25 mins",
  "prerequisites": [
    "Model Evaluation Metrics"
  ],
  "learning_objectives": [
    "train_test_split",
    "K-Fold CV",
    "Stratified K-Fold"
  ],
  "theory": "We split data to simulate unseen data. \n- **Hold-out**: Train (80%) / Test (20%).\n- **K-Fold**: Split into K chunks. Train on K-1, test on 1. Repeat K times. More robust estimate.",
  "syntax": "train_test_split(X, y, test_size=0.2)\ncross_val_score(model, X, y, cv=5)",
  "examples": [],
  "common_mistakes": [
    {
      "mistake": "Leaking information",
      "correction": "Don't perform operations (like imputation or scaling) on the whole dataset before splitting. Split FIRST.",
      "example": "Data Leakage."
    }
  ],
  "interview_questions": [
    {
      "question": "Why use K-Fold over simple split?",
      "answer": "It reduces the variance of the performance estimate. Every data point gets to be in the test set exactly once.",
      "difficulty": "Medium"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "random_state for reproducibility.",
    "Stratified preserves class ratios."
  ],
  "summary": "Rigorous validation prevents the embarrassment of a model failing in production.",
  "order": 47
}