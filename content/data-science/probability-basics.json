{
  "title": "Probability Basics",
  "slug": "probability-basics",
  "subject": "Data Science",
  "category": "Data & Analytics",
  "level": "Intermediate",
  "estimated_read_time": "25 mins",
  "prerequisites": [
    "Descriptive Statistics"
  ],
  "learning_objectives": [
    "Independent Events",
    "Conditional Probability",
    "Bayes' Theorem"
  ],
  "theory": "Probability quantifies uncertainty. \n- **Marginal**: P(A).\n- **Joint**: P(A and B).\n- **Conditional**: P(A|B) = P(A and B) / P(B).\n**Bayes' Theorem** updates beliefs given new evidence.",
  "syntax": "N/A",
  "examples": [
    {
      "code": "P(Rain|Cloudy) = P(Cloudy|Rain) * P(Rain) / P(Cloudy)",
      "output": "Formula",
      "explanation": "Bayes theorem in action."
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Gambler's Fallacy",
      "correction": "Thinking past independent events influence future ones (e.g., 'Red came up 5 times, Black is due').",
      "example": "Coin flips are memoryless."
    }
  ],
  "interview_questions": [
    {
      "question": "What is P(A or B) if events are mutually exclusive?",
      "answer": "P(A) + P(B).",
      "difficulty": "Medium"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [
    {
      "scenario": "Spam Filters",
      "description": "Naive Bayes classifiers use probability to determine if a message is spam given certain words.",
      "code": "P(Spam|Word)"
    }
  ],
  "exam_notes": [
    "Sum rule: P(A or B).",
    "Product rule: P(A and B)."
  ],
  "summary": "Probability is the language of uncertainty in machine learning.",
  "order": 23
}