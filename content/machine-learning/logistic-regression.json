{
  "title": "Logistic Regression",
  "slug": "machine-learning-logistic-regression",
  "subject": "Machine Learning",
  "category": "Artificial Intelligence",
  "level": "Intermediate",
  "estimated_read_time": "35 mins",
  "prerequisites": [
    "Linear Regression"
  ],
  "learning_objectives": [
    "Sigmoid Function",
    "Classification",
    "Decision Boundary",
    "Log Loss"
  ],
  "theory": "Despite the name, it's for **Classification**. \nPredicts Probability (0 to 1) using **Sigmoid** function `1 / (1 + e^-z)`. \nThreshold (usually 0.5) converts prob to class.",
  "syntax": "LogisticRegression()",
  "examples": [],
  "common_mistakes": [
    {
      "mistake": "Thinking it's for Regression",
      "correction": "Output is probability, used for classes. Don't predict price with it.",
      "example": "N/A"
    }
  ],
  "interview_questions": [
    {
      "question": "Why not Linear Regression for Classification?",
      "answer": "Linear regression output is unbounded, can be > 1 or < 0. Sigmoid bounds it.",
      "difficulty": "Easy"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [
    {
      "scenario": "Spam Filter",
      "description": "Prob(Spam) > 0.5 -> Spam Folder.",
      "code": "Email"
    }
  ],
  "exam_notes": [
    "Maximum Likelihood Estimation (MLE) used instead of OLS."
  ],
  "summary": "The S-Curve.",
  "order": 38
}