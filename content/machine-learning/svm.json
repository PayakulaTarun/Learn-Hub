{
  "title": "Support Vector Machines (SVM)",
  "slug": "svm",
  "subject": "Machine Learning",
  "category": "Artificial Intelligence",
  "level": "Intermediate",
  "estimated_read_time": "40 mins",
  "prerequisites": [
    "Linear Regression"
  ],
  "learning_objectives": [
    "Hyperplane",
    "Margin",
    "Support Vectors",
    "Kernel Trick"
  ],
  "theory": "Finding the BEST boundary. \nMaximize the **Margin** (Street width) between classes. \n**Kernel Trick**: Projects data to higher dimensions to make it linearly separable.",
  "syntax": "SVC(kernel='rbf')",
  "examples": [],
  "common_mistakes": [],
  "interview_questions": [
    {
      "question": "What are Support Vectors?",
      "answer": "The data points closest to the hyperplane. Only these matter; removing others doesn't change the line.",
      "difficulty": "Medium"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "C parameter (Regularization)."
  ],
  "summary": "Maximum margin."
}