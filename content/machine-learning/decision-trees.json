{
  "title": "Decision Trees",
  "slug": "machine-learning-decision-trees",
  "subject": "Machine Learning",
  "category": "Artificial Intelligence",
  "level": "Intermediate",
  "estimated_read_time": "35 mins",
  "prerequisites": [
    "Regression vs Classification"
  ],
  "learning_objectives": [
    "Entropy",
    "Information Gain",
    "Gini Impurity",
    "Pruning"
  ],
  "theory": "Flowchart-like model. \nSplits data recursively based on features. \nGoal: Create pure leaf nodes. \nMetric: **Gini** (Probability of misclassification) or **Entropy** (Measure of disorder).",
  "syntax": "DecisionTreeRegressor",
  "examples": [],
  "common_mistakes": [
    {
      "mistake": "Overfitting",
      "correction": "Trees tend to grow until they memorize data. Must use Max Depth or Pruning.",
      "example": "Depth=None."
    }
  ],
  "interview_questions": [
    {
      "question": "Information Gain formula?",
      "answer": "Entropy(Parent) - WeightedAvg(Entropy(Children)).",
      "difficulty": "Advanced"
    }
  ],
  "practice_problems": [],
  "real_world_use_cases": [],
  "exam_notes": [
    "Can handle non-linear data well."
  ],
  "summary": "If This Then That.",
  "order": 36
}